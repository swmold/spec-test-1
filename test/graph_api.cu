/*
 * CUDA Graph API - 통합 모듈
 * 
 * 기능:
 * 1. DOT 파일 저장 (cudaGraphDebugDotPrint)
 * 2. 그래프 노드 수정 (Grid dimension 변경 등)
 * 3. PyTorch CUDAGraph에서 내부 핸들 추출
 */

#include <torch/extension.h>
#include <ATen/cuda/CUDAGraph.h>
#include <c10/cuda/CUDAStream.h>
#include <cuda_runtime.h>
#include <iostream>
#include <fstream>
#include <sstream>
#include <vector>
#include <string>
#include <cmath>
#include <unordered_map>

// CUDA 에러 체크 매크로
#define CUDA_CHECK(call) \
    do { \
        cudaError_t err = call; \
        if (err != cudaSuccess) { \
            throw std::runtime_error(std::string("CUDA Error: ") + cudaGetErrorString(err)); \
        } \
    } while (0)

// ============================================================
// DOT 파일 저장 기능
// ============================================================

// cudaGraphDebugDotFlags
enum GraphDebugDotFlags {
    DOT_FLAGS_DEFAULT = 0,
    DOT_FLAGS_VERBOSE = 1,
    DOT_FLAGS_RUNTIME_TYPES = 2,
    DOT_FLAGS_KERNEL_NODE_PARAMS = 4,
    DOT_FLAGS_MEMCPY_NODE_PARAMS = 8,
    DOT_FLAGS_MEMSET_NODE_PARAMS = 16,
    DOT_FLAGS_HOST_NODE_PARAMS = 32,
    DOT_FLAGS_EVENT_NODE_PARAMS = 64,
    DOT_FLAGS_HANDLES = 1024
};
// 노드 타입 문자열 변환
std::string node_type_to_string(cudaGraphNodeType type) {
    switch (type) {
        case cudaGraphNodeTypeKernel: return "KERNEL";
        case cudaGraphNodeTypeMemcpy: return "MEMCPY";
        case cudaGraphNodeTypeMemset: return "MEMSET";
        case cudaGraphNodeTypeHost: return "HOST";
        case cudaGraphNodeTypeGraph: return "CHILD_GRAPH";
        case cudaGraphNodeTypeEmpty: return "EMPTY";
        case cudaGraphNodeTypeWaitEvent: return "WAIT_EVENT";
        case cudaGraphNodeTypeEventRecord: return "EVENT_RECORD";
        default: return "UNKNOWN";
    }
}
/*
 * cudaGraph_t PyCapsule에서 DOT 파일 저장
 */
bool save_graph_dot_from_capsule(py::object graph_capsule, const std::string& filename, unsigned int flags) {
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        std::cerr << "Error: Expected a PyCapsule object" << std::endl;
        return false;
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        std::cerr << "Error: Could not extract cudaGraph_t from capsule" << std::endl;
        return false;
    }
    
    cudaError_t err = cudaGraphDebugDotPrint(graph, filename.c_str(), flags);
    if (err != cudaSuccess) {
        std::cerr << "CUDA Error: " << cudaGetErrorString(err) << std::endl;
        return false;
    }
    
    std::cout << "Graph saved to: " << filename << std::endl;
    return true;
}

std::string dump_runtime_grid_values(py::object input_obj) {
    std::stringstream ss;
    
    // 그래프 핸들 추출
    cudaGraph_t graph = nullptr;
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
    } else if (py::isinstance<py::int_>(input_obj)) {
        graph = reinterpret_cast<cudaGraph_t>(input_obj.cast<uint64_t>());
    } else {
        return "Error: Input must be PyCapsule or int";
    }

    if (graph == nullptr) return "Error: Invalid graph pointer";

    // 노드 가져오기
    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    if (err != cudaSuccess) return "CUDA Error: " + std::string(cudaGetErrorString(err));

    std::vector<cudaGraphNode_t> nodes(numNodes);
    cudaGraphGetNodes(graph, nodes.data(), &numNodes);

    ss << "# Runtime CUDA Graph Grid Values\n";
    ss << "# Total nodes: " << numNodes << "\n";
    ss << "# Format: {node_id: (grid_x, grid_y, grid_z)}\n\n";
    ss << "runtime_grid_values = {\n";

    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        if (cudaGraphNodeGetType(nodes[i], &type) != cudaSuccess) continue;
        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            memset(&params, 0, sizeof(params));
            
            if (cudaGraphKernelNodeGetParams(nodes[i], &params) == cudaSuccess) {
                ss << "    " << i << ": (" 
                   << params.gridDim.x << ", " 
                   << params.gridDim.y << ", " 
                   << params.gridDim.z << "),\n";
            }
        }
    }
    
    ss << "}\n";
    return ss.str();
}


/*
 * 스트림 캡처를 통해 그래프 생성 및 DOT 저장
 */
py::tuple capture_graph_and_save_dot(
    py::function forward_fn,
    py::object input_tensor,
    const std::string& filename,
    unsigned int flags
) {
    cudaStream_t stream;
    cudaGraph_t graph;
    cudaGraphExec_t graphExec;
    
    CUDA_CHECK(cudaStreamCreate(&stream));
    
    // PyTorch 스트림 설정
    auto torch_cuda = py::module_::import("torch").attr("cuda");
    
    // 그래프 캡처 시작
    CUDA_CHECK(cudaStreamBeginCapture(stream, cudaStreamCaptureModeGlobal));
    
    py::object output;
    try {
        output = forward_fn(input_tensor);
        torch_cuda.attr("synchronize")();
    } catch (const std::exception& e) {
        cudaStreamEndCapture(stream, &graph);
        cudaStreamDestroy(stream);
        throw std::runtime_error(std::string("Error during capture: ") + e.what());
    }
    
    // 그래프 캡처 종료
    CUDA_CHECK(cudaStreamEndCapture(stream, &graph));
    
    // DOT 파일 저장
    if (!filename.empty()) {
        cudaError_t err = cudaGraphDebugDotPrint(graph, filename.c_str(), flags);
        if (err == cudaSuccess) {
            std::cout << "Graph saved to: " << filename << std::endl;
        }
    }
    
    // 그래프 인스턴스화
    CUDA_CHECK(cudaGraphInstantiate(&graphExec, graph, nullptr, nullptr, 0));
    
    // 정리
    cudaStreamDestroy(stream);
    
    // PyCapsule로 반환
    py::capsule graph_capsule(graph, [](void* ptr) {
        if (ptr) cudaGraphDestroy(static_cast<cudaGraph_t>(ptr));
    });
    
    py::capsule exec_capsule(graphExec, [](void* ptr) {
        if (ptr) cudaGraphExecDestroy(static_cast<cudaGraphExec_t>(ptr));
    });
    
    return py::make_tuple(graph_capsule, exec_capsule, output);
}

/*
 * 빈 그래프 생성 후 DOT 저장 테스트
 */
bool test_empty_graph_dot(const std::string& filename) {
    cudaGraph_t graph;
    
    CUDA_CHECK(cudaGraphCreate(&graph, 0));
    CUDA_CHECK(cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE));
    
    std::cout << "Empty graph saved to: " << filename << std::endl;
    
    cudaGraphDestroy(graph);
    return true;
}

/*
 * PyTorch CUDAGraph 객체에서 DOT 파일 저장
 * 
 * PyTorch의 at::cuda::CUDAGraph 클래스를 직접 캐스팅하여 cudaGraph_t 접근
 */
bool save_pytorch_graph_dot(py::object cuda_graph_obj, const std::string& filename, unsigned int flags) {
    // 방법 1: PyTorch C++ 객체로 직접 캐스팅 (at::cuda::CUDAGraph)
    try {
        // torch.cuda.CUDAGraph -> at::cuda::CUDAGraph& 캐스팅
        at::cuda::CUDAGraph& cuda_graph = py::cast<at::cuda::CUDAGraph&>(cuda_graph_obj);
        
        // debug_dump() 호출 (내부적으로 cudaGraphDebugDotPrint 사용)
        cuda_graph.debug_dump(filename);
        
        // 파일 생성 확인
        std::ifstream f(filename);
        if (f.good()) {
            f.seekg(0, std::ios::end);
            size_t size = f.tellg();
            if (size > 0) {
                std::cout << "Saved via at::cuda::CUDAGraph::debug_dump(): " << filename 
                          << " (" << size << " bytes)" << std::endl;
                return true;
            }
        }
    } catch (const py::cast_error& e) {
        std::cerr << "py::cast to at::cuda::CUDAGraph failed: " << e.what() << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "debug_dump() exception: " << e.what() << std::endl;
    }
    
    // 방법 2: Python debug_dump() 메서드 직접 호출 (fallback)
    if (py::hasattr(cuda_graph_obj, "debug_dump")) {
        try {
            cuda_graph_obj.attr("debug_dump")(filename);
            
            std::ifstream f(filename);
            if (f.good()) {
                f.seekg(0, std::ios::end);
                size_t size = f.tellg();
                if (size > 0) {
                    std::cout << "Saved via Python debug_dump(): " << filename 
                              << " (" << size << " bytes)" << std::endl;
                    return true;
                }
            }
        } catch (const std::exception& e) {
            std::cerr << "Python debug_dump() exception: " << e.what() << std::endl;
        }
    }
    
    std::cerr << "Failed to save DOT file from PyTorch CUDAGraph" << std::endl;
    return false;
}

/*
 * PyTorch CUDAGraph 객체에서 노드 정보 추출
 */
py::list get_pytorch_graph_nodes_info(py::object cuda_graph_obj) {
    py::list nodes_info;
    
    try {
        at::cuda::CUDAGraph& cuda_graph = py::cast<at::cuda::CUDAGraph&>(cuda_graph_obj);
        std::cerr << "get_pytorch_graph_nodes_info: Direct node access not available" << std::endl;
    } catch (const py::cast_error& e) {
        std::cerr << "Cast error: " << e.what() << std::endl;
    }
    
    return nodes_info;
}

/*
 * PyTorch CUDAGraph 기본 정보 출력 및 DOT 파일 저장
 */
std::string print_pytorch_graph_info(py::object cuda_graph_obj, const std::string& filename) {
    std::stringstream ss;
    
    ss << "========================================\n";
    ss << "PyTorch CUDA Graph Info\n";
    ss << "========================================\n";
    
    try {
        at::cuda::CUDAGraph& cuda_graph = py::cast<at::cuda::CUDAGraph&>(cuda_graph_obj);
        
        ss << "Type: torch.cuda.CUDAGraph\n";
        ss << "Status: Captured\n";
        
        // pool 정보 확인
        if (py::hasattr(cuda_graph_obj, "pool")) {
            ss << "Memory Pool: Available\n";
        }
        
        // DOT 파일 저장 (debug_dump 메서드 사용)
        if (!filename.empty()) {
            try {
                cuda_graph.debug_dump(filename);
                
                // 파일 생성 확인
                std::ifstream f(filename);
                if (f.good()) {
                    f.seekg(0, std::ios::end);
                    size_t size = f.tellg();
                    ss << "DOT file saved: " << filename << " (" << size << " bytes)\n";
                } else {
                    ss << "DOT file may not have been created , filename: " << filename << std::endl;
                }
            } catch (const std::exception& e) {
                ss << "DOT save failed: " << e.what() << "\n";
            }
        }

        ss << "========================================\n";
        
    } catch (const py::cast_error& e) {
        ss << "Error: Could not cast to at::cuda::CUDAGraph\n";
        ss << "Details: " << e.what() << "\n";
    } catch (const std::exception& e) {
        ss << "Error: " << e.what() << "\n";
    }
    
    ss << "========================================\n";
    return ss.str();
}
std::string debug_all_graph_nodes(py::object input_obj) {
    std::stringstream ss;
    ss << "=== FULL GRAPH DEBUG ===\n";
    
    cudaGraph_t graph = nullptr;
    // ... (핸들 추출 로직 동일) ...
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
    } else if (py::isinstance<py::int_>(input_obj)) {
        graph = reinterpret_cast<cudaGraph_t>(input_obj.cast<uint64_t>());
    }

    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    if (err != cudaSuccess) return "Failed to get num nodes";
    
    ss << "Total Nodes: " << numNodes << "\n";
    
    std::vector<cudaGraphNode_t> nodes(numNodes);
    cudaGraphGetNodes(graph, nodes.data(), &numNodes);

    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        cudaGraphNodeGetType(nodes[i], &type);
        
        ss << "Node " << i << ": Type=" << (int)type;
        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            memset(&params, 0, sizeof(params));
            err = cudaGraphKernelNodeGetParams(nodes[i], &params);
            
            if (err == cudaSuccess) {
                ss << " | Grid=(" << params.gridDim.x << "," 
                   << params.gridDim.y << "," << params.gridDim.z << ")";
                   
                // Cutlass 1번 노드 특징 확인
                if (params.gridDim.y == 48 || params.gridDim.y == 32) {
                    ss << " <--- CANDIDATE!";
                }
            } else {
                ss << " | GetParams Error: " << cudaGetErrorString(err);
            }
        }
        ss << "\n";
    }
    return ss.str();
}


/*
 * Cutlass GEMM 커널 파라미터 정밀 분석 함수
 * Heuristic: Grid Y가 32 또는 48인 노드만 타겟팅
 */
std::string inspect_cutlass_gemm_params(py::object input_obj) {
    std::stringstream ss;

    ss << "========================================\n";
    ss << "Inspecting Cutlass GEMM Params (Heuristic: Grid.y == 32 or 48)\n";
    ss << "========================================\n";

    // 1. 디바이스 동기화 (안전장치)
    cudaDeviceSynchronize();

    // 2. 그래프 핸들 추출
    cudaGraph_t graph = nullptr;
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
    } else if (py::isinstance<py::int_>(input_obj)) {
        graph = reinterpret_cast<cudaGraph_t>(input_obj.cast<uint64_t>());
    } else {
        return "Error: Input must be PyCapsule or int";
    }

    if (graph == nullptr) return "Error: Invalid graph pointer";

    // 3. 노드 가져오기
    size_t numNodes = 0;
    cudaGraphGetNodes(graph, nullptr, &numNodes);
    std::vector<cudaGraphNode_t> nodes(numNodes);
    cudaGraphGetNodes(graph, nodes.data(), &numNodes);

    int found_count = 0;

    // 4. 노드 순회
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        if (cudaGraphNodeGetType(nodes[i], &type) != cudaSuccess) continue;

        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            memset(&params, 0, sizeof(params)); // 0 초기화 필수
            
            if (cudaGraphKernelNodeGetParams(nodes[i], &params) != cudaSuccess) {
                cudaGetLastError(); continue;
                ss << "\n[Node " << i << "] | KERNEL (params unavailable)\n";
            }

            dim3 grid = params.gridDim;

            // [Heuristic] Cutlass Pattern Check
            found_count++;
            ss << "\n[Node " << i << "] | Grid: (" 
                << grid.x << ", " << grid.y << ", " << grid.z << ")\n";

            if (params.kernelParams == nullptr) {
                ss << "  -> kernelParams is nullptr\n";
                continue;
            }

            // Cutlass는 보통 첫 번째 인자(Params 구조체)에 모든 설정이 들어있음
            // 구조체의 내용을 256바이트(64개 int) 정도 읽어서 덤프합니다.
            void* param_struct_ptr = params.kernelParams[0];
            
            if (param_struct_ptr != nullptr) {
                ss << "  -> Dumping First Argument (Assuming 'struct Params') memory:\n";
                ss << "     (Looking for integer values like 8, 16, 4096, 128...)\n";
                
                // 메모리 읽기 (안전하게 Try-Catch 유사 처리 필요하지만, 여기선 직접 읽음)
                // 실제로는 kernelParams[0]이 가리키는 곳이 Host 메모리인지 Device 메모리인지에 따라 다름
                // CUDA Graph 파라미터는 보통 Host 측 섀도우 카피를 가리킵니다.
                
                int* int_view = static_cast<int*>(param_struct_ptr);
                
                // 64개의 int (256 bytes) 출력
                for (int k = 0; k < 64; k++) {
                    // 4개씩 끊어서 출력
                    if (k % 4 == 0) ss << "    Offset " << std::setw(3) << (k*4) << ": ";
                    
                    int val = 0;
                    // 안전하게 메모리 복사 (혹시 모를 Alignment 문제 방지)
                    memcpy(&val, &int_view[k], sizeof(int));
                    
                    ss << std::setw(12) << val;
                    
                    // [중요] 우리가 찾는 Batch Size 후보가 보이면 표시
                    if (val == 8 || val == 16 || val == 32 || val == 128) {
                            ss << " <*>";
                    }
                    
                    if (k % 4 == 3) ss << "\n";
                }
            }
        }
    }

    ss << "\n========================================\n";
    ss << "Total Cutlass Kernels Found: " << found_count << "\n";
    ss << "========================================\n";

    return ss.str();
}

/*
 * Llama-3.1-8B-Instruct 모델 전용 그래프 수정 함수
 * 
 * 새로운 방식:
 * 1. Node Index 기반 정확한 매핑 테이블 사용
 * 2. cudagraph_batch_16.dot와 cudagraph_batch_9.dot 비교 분석으로 생성된 매핑
 * 3. cudaGraphKernelNodeGetParams 실패 시 raw data에서 직접 읽기
 */

// Node-by-Node Grid Mapping Structure
struct NodeGridMapping {
    int node_id;
    unsigned int src_x, src_y, src_z;
    unsigned int tgt_x, tgt_y, tgt_z;
};

// Batch 16 -> 9 Node-specific mapping (from runtime debug files)
static const NodeGridMapping NODE_GRID_MAP_16_TO_9[] = {
    {0, 16,1,1, 9,1,1},
    {1, 8,48,1, 8,48,1},
    {2, 160,1,1, 90,1,1},
    {3, 16,1,1, 9,1,1},
    {4, 128,1,1, 72,1,1},
    {5, 1,2,128, 1,7,72},
    {6, 128,1,1, 72,1,1},
    {7, 128,1,1, 72,1,1},
    {8, 8,32,1, 8,32,1},
    {9, 16,1,1, 9,1,1},
    {10, 8,224,1, 8,224,1},
    {11, 448,1,1, 252,1,1},
    {12, 8,32,1, 8,32,1},
    {13, 16,1,1, 9,1,1},
    {14, 8,48,1, 8,48,1},
    {15, 160,1,1, 90,1,1},
    {16, 16,1,1, 9,1,1},
    {17, 128,1,1, 72,1,1},
    {18, 1,2,128, 1,7,72},
    {19, 128,1,1, 72,1,1},
    {20, 128,1,1, 72,1,1},
    {21, 8,32,1, 8,32,1},
    {22, 16,1,1, 9,1,1},
    {23, 8,224,1, 8,224,1},
    {24, 448,1,1, 252,1,1},
    {25, 8,32,1, 8,32,1},
    {26, 16,1,1, 9,1,1},
    {27, 8,48,1, 8,48,1},
    {28, 160,1,1, 90,1,1},
    {29, 16,1,1, 9,1,1},
    {30, 128,1,1, 72,1,1},
    {31, 1,2,128, 1,7,72},
    {32, 128,1,1, 72,1,1},
    {33, 128,1,1, 72,1,1},
    {34, 8,32,1, 8,32,1},
    {35, 16,1,1, 9,1,1},
    {36, 8,224,1, 8,224,1},
    {37, 448,1,1, 252,1,1},
    {38, 8,32,1, 8,32,1},
    {39, 16,1,1, 9,1,1},
    {40, 8,48,1, 8,48,1},
    {41, 160,1,1, 90,1,1},
    {42, 16,1,1, 9,1,1},
    {43, 128,1,1, 72,1,1},
    {44, 1,2,128, 1,7,72},
    {45, 128,1,1, 72,1,1},
    {46, 128,1,1, 72,1,1},
    {47, 8,32,1, 8,32,1},
    {48, 16,1,1, 9,1,1},
    {49, 8,224,1, 8,224,1},
    {50, 448,1,1, 252,1,1},
    {51, 8,32,1, 8,32,1},
    {52, 16,1,1, 9,1,1},
    {53, 8,48,1, 8,48,1},
    {54, 160,1,1, 90,1,1},
    {55, 16,1,1, 9,1,1},
    {56, 128,1,1, 72,1,1},
    {57, 1,2,128, 1,7,72},
    {58, 128,1,1, 72,1,1},
    {59, 128,1,1, 72,1,1},
    {60, 8,32,1, 8,32,1},
    {61, 16,1,1, 9,1,1},
    {62, 8,224,1, 8,224,1},
    {63, 448,1,1, 252,1,1},
    {64, 8,32,1, 8,32,1},
    {65, 16,1,1, 9,1,1},
    {66, 8,48,1, 8,48,1},
    {67, 160,1,1, 90,1,1},
    {68, 16,1,1, 9,1,1},
    {69, 128,1,1, 72,1,1},
    {70, 1,2,128, 1,7,72},
    {71, 128,1,1, 72,1,1},
    {72, 128,1,1, 72,1,1},
    {73, 8,32,1, 8,32,1},
    {74, 16,1,1, 9,1,1},
    {75, 8,224,1, 8,224,1},
    {76, 448,1,1, 252,1,1},
    {77, 8,32,1, 8,32,1},
    {78, 16,1,1, 9,1,1},
    {79, 8,48,1, 8,48,1},
    {80, 160,1,1, 90,1,1},
    {81, 16,1,1, 9,1,1},
    {82, 128,1,1, 72,1,1},
    {83, 1,2,128, 1,7,72},
    {84, 128,1,1, 72,1,1},
    {85, 128,1,1, 72,1,1},
    {86, 8,32,1, 8,32,1},
    {87, 16,1,1, 9,1,1},
    {88, 8,224,1, 8,224,1},
    {89, 448,1,1, 252,1,1},
    {90, 8,32,1, 8,32,1},
    {91, 16,1,1, 9,1,1},
    {92, 8,48,1, 8,48,1},
    {93, 160,1,1, 90,1,1},
    {94, 16,1,1, 9,1,1},
    {95, 128,1,1, 72,1,1},
    {96, 1,2,128, 1,7,72},
    {97, 128,1,1, 72,1,1},
    {98, 128,1,1, 72,1,1},
    {99, 8,32,1, 8,32,1},
    {100, 16,1,1, 9,1,1},
    {101, 8,224,1, 8,224,1},
    {102, 448,1,1, 252,1,1},
    {103, 8,32,1, 8,32,1},
    {104, 16,1,1, 9,1,1},
    {105, 8,48,1, 8,48,1},
    {106, 160,1,1, 90,1,1},
    {107, 16,1,1, 9,1,1},
    {108, 128,1,1, 72,1,1},
    {109, 1,2,128, 1,7,72},
    {110, 128,1,1, 72,1,1},
    {111, 128,1,1, 72,1,1},
    {112, 8,32,1, 8,32,1},
    {113, 16,1,1, 9,1,1},
    {114, 8,224,1, 8,224,1},
    {115, 448,1,1, 252,1,1},
    {116, 8,32,1, 8,32,1},
    {117, 16,1,1, 9,1,1},
    {118, 8,48,1, 8,48,1},
    {119, 160,1,1, 90,1,1},
    {120, 16,1,1, 9,1,1},
    {121, 128,1,1, 72,1,1},
    {122, 1,2,128, 1,7,72},
    {123, 128,1,1, 72,1,1},
    {124, 128,1,1, 72,1,1},
    {125, 8,32,1, 8,32,1},
    {126, 16,1,1, 9,1,1},
    {127, 8,224,1, 8,224,1},
    {128, 448,1,1, 252,1,1},
    {129, 8,32,1, 8,32,1},
    {130, 16,1,1, 9,1,1},
    {131, 8,48,1, 8,48,1},
    {132, 160,1,1, 90,1,1},
    {133, 16,1,1, 9,1,1},
    {134, 128,1,1, 72,1,1},
    {135, 1,2,128, 1,7,72},
    {136, 128,1,1, 72,1,1},
    {137, 128,1,1, 72,1,1},
    {138, 8,32,1, 8,32,1},
    {139, 16,1,1, 9,1,1},
    {140, 8,224,1, 8,224,1},
    {141, 448,1,1, 252,1,1},
    {142, 8,32,1, 8,32,1},
    {143, 16,1,1, 9,1,1},
    {144, 8,48,1, 8,48,1},
    {145, 160,1,1, 90,1,1},
    {146, 16,1,1, 9,1,1},
    {147, 128,1,1, 72,1,1},
    {148, 1,2,128, 1,7,72},
    {149, 128,1,1, 72,1,1},
    {150, 128,1,1, 72,1,1},
    {151, 8,32,1, 8,32,1},
    {152, 16,1,1, 9,1,1},
    {153, 8,224,1, 8,224,1},
    {154, 448,1,1, 252,1,1},
    {155, 8,32,1, 8,32,1},
    {156, 16,1,1, 9,1,1},
    {157, 8,48,1, 8,48,1},
    {158, 160,1,1, 90,1,1},
    {159, 16,1,1, 9,1,1},
    {160, 128,1,1, 72,1,1},
    {161, 1,2,128, 1,7,72},
    {162, 128,1,1, 72,1,1},
    {163, 128,1,1, 72,1,1},
    {164, 8,32,1, 8,32,1},
    {165, 16,1,1, 9,1,1},
    {166, 8,224,1, 8,224,1},
    {167, 448,1,1, 252,1,1},
    {168, 8,32,1, 8,32,1},
    {169, 16,1,1, 9,1,1},
    {170, 8,48,1, 8,48,1},
    {171, 160,1,1, 90,1,1},
    {172, 16,1,1, 9,1,1},
    {173, 128,1,1, 72,1,1},
    {174, 1,2,128, 1,7,72},
    {175, 128,1,1, 72,1,1},
    {176, 128,1,1, 72,1,1},
    {177, 8,32,1, 8,32,1},
    {178, 16,1,1, 9,1,1},
    {179, 8,224,1, 8,224,1},
    {180, 448,1,1, 252,1,1},
    {181, 8,32,1, 8,32,1},
    {182, 16,1,1, 9,1,1},
    {183, 8,48,1, 8,48,1},
    {184, 160,1,1, 90,1,1},
    {185, 16,1,1, 9,1,1},
    {186, 128,1,1, 72,1,1},
    {187, 1,2,128, 1,7,72},
    {188, 128,1,1, 72,1,1},
    {189, 128,1,1, 72,1,1},
    {190, 8,32,1, 8,32,1},
    {191, 16,1,1, 9,1,1},
    {192, 8,224,1, 8,224,1},
    {193, 448,1,1, 252,1,1},
    {194, 8,32,1, 8,32,1},
    {195, 16,1,1, 9,1,1},
    {196, 8,48,1, 8,48,1},
    {197, 160,1,1, 90,1,1},
    {198, 16,1,1, 9,1,1},
    {199, 128,1,1, 72,1,1},
    {200, 1,2,128, 1,7,72},
    {201, 128,1,1, 72,1,1},
    {202, 128,1,1, 72,1,1},
    {203, 8,32,1, 8,32,1},
    {204, 16,1,1, 9,1,1},
    {205, 8,224,1, 8,224,1},
    {206, 448,1,1, 252,1,1},
    {207, 8,32,1, 8,32,1},
    {208, 16,1,1, 9,1,1},
    {209, 8,48,1, 8,48,1},
    {210, 160,1,1, 90,1,1},
    {211, 16,1,1, 9,1,1},
    {212, 128,1,1, 72,1,1},
    {213, 1,2,128, 1,7,72},
    {214, 128,1,1, 72,1,1},
    {215, 128,1,1, 72,1,1},
    {216, 8,32,1, 8,32,1},
    {217, 16,1,1, 9,1,1},
    {218, 8,224,1, 8,224,1},
    {219, 448,1,1, 252,1,1},
    {220, 8,32,1, 8,32,1},
    {221, 16,1,1, 9,1,1},
    {222, 8,48,1, 8,48,1},
    {223, 160,1,1, 90,1,1},
    {224, 16,1,1, 9,1,1},
    {225, 128,1,1, 72,1,1},
    {226, 1,2,128, 1,7,72},
    {227, 128,1,1, 72,1,1},
    {228, 128,1,1, 72,1,1},
    {229, 8,32,1, 8,32,1},
    {230, 16,1,1, 9,1,1},
    {231, 8,224,1, 8,224,1},
    {232, 448,1,1, 252,1,1},
    {233, 8,32,1, 8,32,1},
    {234, 16,1,1, 9,1,1},
    {235, 8,48,1, 8,48,1},
    {236, 160,1,1, 90,1,1},
    {237, 16,1,1, 9,1,1},
    {238, 128,1,1, 72,1,1},
    {239, 1,2,128, 1,7,72},
    {240, 128,1,1, 72,1,1},
    {241, 128,1,1, 72,1,1},
    {242, 8,32,1, 8,32,1},
    {243, 16,1,1, 9,1,1},
    {244, 8,224,1, 8,224,1},
    {245, 448,1,1, 252,1,1},
    {246, 8,32,1, 8,32,1},
    {247, 16,1,1, 9,1,1},
    {248, 8,48,1, 8,48,1},
    {249, 160,1,1, 90,1,1},
    {250, 16,1,1, 9,1,1},
    {251, 128,1,1, 72,1,1},
    {252, 1,2,128, 1,7,72},
    {253, 128,1,1, 72,1,1},
    {254, 128,1,1, 72,1,1},
    {255, 8,32,1, 8,32,1},
    {256, 16,1,1, 9,1,1},
    {257, 8,224,1, 8,224,1},
    {258, 448,1,1, 252,1,1},
    {259, 8,32,1, 8,32,1},
    {260, 16,1,1, 9,1,1},
    {261, 8,48,1, 8,48,1},
    {262, 160,1,1, 90,1,1},
    {263, 16,1,1, 9,1,1},
    {264, 128,1,1, 72,1,1},
    {265, 1,2,128, 1,7,72},
    {266, 128,1,1, 72,1,1},
    {267, 128,1,1, 72,1,1},
    {268, 8,32,1, 8,32,1},
    {269, 16,1,1, 9,1,1},
    {270, 8,224,1, 8,224,1},
    {271, 448,1,1, 252,1,1},
    {272, 8,32,1, 8,32,1},
    {273, 16,1,1, 9,1,1},
    {274, 8,48,1, 8,48,1},
    {275, 160,1,1, 90,1,1},
    {276, 16,1,1, 9,1,1},
    {277, 128,1,1, 72,1,1},
    {278, 1,2,128, 1,7,72},
    {279, 128,1,1, 72,1,1},
    {280, 128,1,1, 72,1,1},
    {281, 8,32,1, 8,32,1},
    {282, 16,1,1, 9,1,1},
    {283, 8,224,1, 8,224,1},
    {284, 448,1,1, 252,1,1},
    {285, 8,32,1, 8,32,1},
    {286, 16,1,1, 9,1,1},
    {287, 8,48,1, 8,48,1},
    {288, 160,1,1, 90,1,1},
    {289, 16,1,1, 9,1,1},
    {290, 128,1,1, 72,1,1},
    {291, 1,2,128, 1,7,72},
    {292, 128,1,1, 72,1,1},
    {293, 128,1,1, 72,1,1},
    {294, 8,32,1, 8,32,1},
    {295, 16,1,1, 9,1,1},
    {296, 8,224,1, 8,224,1},
    {297, 448,1,1, 252,1,1},
    {298, 8,32,1, 8,32,1},
    {299, 16,1,1, 9,1,1},
    {300, 8,48,1, 8,48,1},
    {301, 160,1,1, 90,1,1},
    {302, 16,1,1, 9,1,1},
    {303, 128,1,1, 72,1,1},
    {304, 1,2,128, 1,7,72},
    {305, 128,1,1, 72,1,1},
    {306, 128,1,1, 72,1,1},
    {307, 8,32,1, 8,32,1},
    {308, 16,1,1, 9,1,1},
    {309, 8,224,1, 8,224,1},
    {310, 448,1,1, 252,1,1},
    {311, 8,32,1, 8,32,1},
    {312, 16,1,1, 9,1,1},
    {313, 8,48,1, 8,48,1},
    {314, 160,1,1, 90,1,1},
    {315, 16,1,1, 9,1,1},
    {316, 128,1,1, 72,1,1},
    {317, 1,2,128, 1,7,72},
    {318, 128,1,1, 72,1,1},
    {319, 128,1,1, 72,1,1},
    {320, 8,32,1, 8,32,1},
    {321, 16,1,1, 9,1,1},
    {322, 8,224,1, 8,224,1},
    {323, 448,1,1, 252,1,1},
    {324, 8,32,1, 8,32,1},
    {325, 16,1,1, 9,1,1},
    {326, 8,48,1, 8,48,1},
    {327, 160,1,1, 90,1,1},
    {328, 16,1,1, 9,1,1},
    {329, 128,1,1, 72,1,1},
    {330, 1,2,128, 1,7,72},
    {331, 128,1,1, 72,1,1},
    {332, 128,1,1, 72,1,1},
    {333, 8,32,1, 8,32,1},
    {334, 16,1,1, 9,1,1},
    {335, 8,224,1, 8,224,1},
    {336, 448,1,1, 252,1,1},
    {337, 8,32,1, 8,32,1},
    {338, 16,1,1, 9,1,1},
    {339, 8,48,1, 8,48,1},
    {340, 160,1,1, 90,1,1},
    {341, 16,1,1, 9,1,1},
    {342, 128,1,1, 72,1,1},
    {343, 1,2,128, 1,7,72},
    {344, 128,1,1, 72,1,1},
    {345, 128,1,1, 72,1,1},
    {346, 8,32,1, 8,32,1},
    {347, 16,1,1, 9,1,1},
    {348, 8,224,1, 8,224,1},
    {349, 448,1,1, 252,1,1},
    {350, 8,32,1, 8,32,1},
    {351, 16,1,1, 9,1,1},
    {352, 8,48,1, 8,48,1},
    {353, 160,1,1, 90,1,1},
    {354, 16,1,1, 9,1,1},
    {355, 128,1,1, 72,1,1},
    {356, 1,2,128, 1,7,72},
    {357, 128,1,1, 72,1,1},
    {358, 128,1,1, 72,1,1},
    {359, 8,32,1, 8,32,1},
    {360, 16,1,1, 9,1,1},
    {361, 8,224,1, 8,224,1},
    {362, 448,1,1, 252,1,1},
    {363, 8,32,1, 8,32,1},
    {364, 16,1,1, 9,1,1},
    {365, 8,48,1, 8,48,1},
    {366, 160,1,1, 90,1,1},
    {367, 16,1,1, 9,1,1},
    {368, 128,1,1, 72,1,1},
    {369, 1,2,128, 1,7,72},
    {370, 128,1,1, 72,1,1},
    {371, 128,1,1, 72,1,1},
    {372, 8,32,1, 8,32,1},
    {373, 16,1,1, 9,1,1},
    {374, 8,224,1, 8,224,1},
    {375, 448,1,1, 252,1,1},
    {376, 8,32,1, 8,32,1},
    {377, 16,1,1, 9,1,1},
    {378, 8,48,1, 8,48,1},
    {379, 160,1,1, 90,1,1},
    {380, 16,1,1, 9,1,1},
    {381, 128,1,1, 72,1,1},
    {382, 1,2,128, 1,7,72},
    {383, 128,1,1, 72,1,1},
    {384, 128,1,1, 72,1,1},
    {385, 8,32,1, 8,32,1},
    {386, 16,1,1, 9,1,1},
    {387, 8,224,1, 8,224,1},
    {388, 448,1,1, 252,1,1},
    {389, 8,32,1, 8,32,1},
    {390, 16,1,1, 9,1,1},
    {391, 8,48,1, 8,48,1},
    {392, 160,1,1, 90,1,1},
    {393, 16,1,1, 9,1,1},
    {394, 128,1,1, 72,1,1},
    {395, 1,2,128, 1,7,72},
    {396, 128,1,1, 72,1,1},
    {397, 128,1,1, 72,1,1},
    {398, 8,32,1, 8,32,1},
    {399, 16,1,1, 9,1,1},
    {400, 8,224,1, 8,224,1},
    {401, 448,1,1, 252,1,1},
    {402, 8,32,1, 8,32,1},
    {403, 16,1,1, 9,1,1},
    {404, 8,48,1, 8,48,1},
    {405, 160,1,1, 90,1,1},
    {406, 16,1,1, 9,1,1},
    {407, 128,1,1, 72,1,1},
    {408, 1,2,128, 1,7,72},
    {409, 128,1,1, 72,1,1},
    {410, 128,1,1, 72,1,1},
    {411, 8,32,1, 8,32,1},
    {412, 16,1,1, 9,1,1},
    {413, 8,224,1, 8,224,1},
    {414, 448,1,1, 252,1,1},
    {415, 8,32,1, 8,32,1},
    {416, 16,1,1, 9,1,1}
};
int NUM_NODE_MAPPINGS_16_TO_9 = sizeof(NODE_GRID_MAP_16_TO_9) / sizeof(NODE_GRID_MAP_16_TO_9[0]);

// Batch 8 -> 5 Node-specific mapping (from runtime debug files)
static const NodeGridMapping NODE_GRID_MAP_8_TO_5[] = {
    {0, 8,1,1, 5,1,1},
    {1, 8,48,1, 8,48,1},
    {2, 80,1,1, 50,1,1},
    {3, 8,1,1, 5,1,1},
    {4, 64,1,1, 40,1,1},
    {5, 1,4,64, 1,6,40},
    {6, 64,1,1, 40,1,1},
    {7, 64,1,1, 40,1,1},
    {8, 8,32,1, 8,32,1},
    {9, 8,1,1, 5,1,1},
    {10, 8,224,1, 8,224,1},
    {11, 224,1,1, 140,1,1},
    {12, 8,32,1, 8,32,1},
    {13, 8,1,1, 5,1,1},
    {14, 8,48,1, 8,48,1},
    {15, 80,1,1, 50,1,1},
    {16, 8,1,1, 5,1,1},
    {17, 64,1,1, 40,1,1},
    {18, 1,4,64, 1,6,40},
    {19, 64,1,1, 40,1,1},
    {20, 64,1,1, 40,1,1},
    {21, 8,32,1, 8,32,1},
    {22, 8,1,1, 5,1,1},
    {23, 8,224,1, 8,224,1},
    {24, 224,1,1, 140,1,1},
    {25, 8,32,1, 8,32,1},
    {26, 8,1,1, 5,1,1},
    {27, 8,48,1, 8,48,1},
    {28, 80,1,1, 50,1,1},
    {29, 8,1,1, 5,1,1},
    {30, 64,1,1, 40,1,1},
    {31, 1,4,64, 1,6,40},
    {32, 64,1,1, 40,1,1},
    {33, 64,1,1, 40,1,1},
    {34, 8,32,1, 8,32,1},
    {35, 8,1,1, 5,1,1},
    {36, 8,224,1, 8,224,1},
    {37, 224,1,1, 140,1,1},
    {38, 8,32,1, 8,32,1},
    {39, 8,1,1, 5,1,1},
    {40, 8,48,1, 8,48,1},
    {41, 80,1,1, 50,1,1},
    {42, 8,1,1, 5,1,1},
    {43, 64,1,1, 40,1,1},
    {44, 1,4,64, 1,6,40},
    {45, 64,1,1, 40,1,1},
    {46, 64,1,1, 40,1,1},
    {47, 8,32,1, 8,32,1},
    {48, 8,1,1, 5,1,1},
    {49, 8,224,1, 8,224,1},
    {50, 224,1,1, 140,1,1},
    {51, 8,32,1, 8,32,1},
    {52, 8,1,1, 5,1,1},
    {53, 8,48,1, 8,48,1},
    {54, 80,1,1, 50,1,1},
    {55, 8,1,1, 5,1,1},
    {56, 64,1,1, 40,1,1},
    {57, 1,4,64, 1,6,40},
    {58, 64,1,1, 40,1,1},
    {59, 64,1,1, 40,1,1},
    {60, 8,32,1, 8,32,1},
    {61, 8,1,1, 5,1,1},
    {62, 8,224,1, 8,224,1},
    {63, 224,1,1, 140,1,1},
    {64, 8,32,1, 8,32,1},
    {65, 8,1,1, 5,1,1},
    {66, 8,48,1, 8,48,1},
    {67, 80,1,1, 50,1,1},
    {68, 8,1,1, 5,1,1},
    {69, 64,1,1, 40,1,1},
    {70, 1,4,64, 1,6,40},
    {71, 64,1,1, 40,1,1},
    {72, 64,1,1, 40,1,1},
    {73, 8,32,1, 8,32,1},
    {74, 8,1,1, 5,1,1},
    {75, 8,224,1, 8,224,1},
    {76, 224,1,1, 140,1,1},
    {77, 8,32,1, 8,32,1},
    {78, 8,1,1, 5,1,1},
    {79, 8,48,1, 8,48,1},
    {80, 80,1,1, 50,1,1},
    {81, 8,1,1, 5,1,1},
    {82, 64,1,1, 40,1,1},
    {83, 1,4,64, 1,6,40},
    {84, 64,1,1, 40,1,1},
    {85, 64,1,1, 40,1,1},
    {86, 8,32,1, 8,32,1},
    {87, 8,1,1, 5,1,1},
    {88, 8,224,1, 8,224,1},
    {89, 224,1,1, 140,1,1},
    {90, 8,32,1, 8,32,1},
    {91, 8,1,1, 5,1,1},
    {92, 8,48,1, 8,48,1},
    {93, 80,1,1, 50,1,1},
    {94, 8,1,1, 5,1,1},
    {95, 64,1,1, 40,1,1},
    {96, 1,4,64, 1,6,40},
    {97, 64,1,1, 40,1,1},
    {98, 64,1,1, 40,1,1},
    {99, 8,32,1, 8,32,1},
    {100, 8,1,1, 5,1,1},
    {101, 8,224,1, 8,224,1},
    {102, 224,1,1, 140,1,1},
    {103, 8,32,1, 8,32,1},
    {104, 8,1,1, 5,1,1},
    {105, 8,48,1, 8,48,1},
    {106, 80,1,1, 50,1,1},
    {107, 8,1,1, 5,1,1},
    {108, 64,1,1, 40,1,1},
    {109, 1,4,64, 1,6,40},
    {110, 64,1,1, 40,1,1},
    {111, 64,1,1, 40,1,1},
    {112, 8,32,1, 8,32,1},
    {113, 8,1,1, 5,1,1},
    {114, 8,224,1, 8,224,1},
    {115, 224,1,1, 140,1,1},
    {116, 8,32,1, 8,32,1},
    {117, 8,1,1, 5,1,1},
    {118, 8,48,1, 8,48,1},
    {119, 80,1,1, 50,1,1},
    {120, 8,1,1, 5,1,1},
    {121, 64,1,1, 40,1,1},
    {122, 1,4,64, 1,6,40},
    {123, 64,1,1, 40,1,1},
    {124, 64,1,1, 40,1,1},
    {125, 8,32,1, 8,32,1},
    {126, 8,1,1, 5,1,1},
    {127, 8,224,1, 8,224,1},
    {128, 224,1,1, 140,1,1},
    {129, 8,32,1, 8,32,1},
    {130, 8,1,1, 5,1,1},
    {131, 8,48,1, 8,48,1},
    {132, 80,1,1, 50,1,1},
    {133, 8,1,1, 5,1,1},
    {134, 64,1,1, 40,1,1},
    {135, 1,4,64, 1,6,40},
    {136, 64,1,1, 40,1,1},
    {137, 64,1,1, 40,1,1},
    {138, 8,32,1, 8,32,1},
    {139, 8,1,1, 5,1,1},
    {140, 8,224,1, 8,224,1},
    {141, 224,1,1, 140,1,1},
    {142, 8,32,1, 8,32,1},
    {143, 8,1,1, 5,1,1},
    {144, 8,48,1, 8,48,1},
    {145, 80,1,1, 50,1,1},
    {146, 8,1,1, 5,1,1},
    {147, 64,1,1, 40,1,1},
    {148, 1,4,64, 1,6,40},
    {149, 64,1,1, 40,1,1},
    {150, 64,1,1, 40,1,1},
    {151, 8,32,1, 8,32,1},
    {152, 8,1,1, 5,1,1},
    {153, 8,224,1, 8,224,1},
    {154, 224,1,1, 140,1,1},
    {155, 8,32,1, 8,32,1},
    {156, 8,1,1, 5,1,1},
    {157, 8,48,1, 8,48,1},
    {158, 80,1,1, 50,1,1},
    {159, 8,1,1, 5,1,1},
    {160, 64,1,1, 40,1,1},
    {161, 1,4,64, 1,6,40},
    {162, 64,1,1, 40,1,1},
    {163, 64,1,1, 40,1,1},
    {164, 8,32,1, 8,32,1},
    {165, 8,1,1, 5,1,1},
    {166, 8,224,1, 8,224,1},
    {167, 224,1,1, 140,1,1},
    {168, 8,32,1, 8,32,1},
    {169, 8,1,1, 5,1,1},
    {170, 8,48,1, 8,48,1},
    {171, 80,1,1, 50,1,1},
    {172, 8,1,1, 5,1,1},
    {173, 64,1,1, 40,1,1},
    {174, 1,4,64, 1,6,40},
    {175, 64,1,1, 40,1,1},
    {176, 64,1,1, 40,1,1},
    {177, 8,32,1, 8,32,1},
    {178, 8,1,1, 5,1,1},
    {179, 8,224,1, 8,224,1},
    {180, 224,1,1, 140,1,1},
    {181, 8,32,1, 8,32,1},
    {182, 8,1,1, 5,1,1},
    {183, 8,48,1, 8,48,1},
    {184, 80,1,1, 50,1,1},
    {185, 8,1,1, 5,1,1},
    {186, 64,1,1, 40,1,1},
    {187, 1,4,64, 1,6,40},
    {188, 64,1,1, 40,1,1},
    {189, 64,1,1, 40,1,1},
    {190, 8,32,1, 8,32,1},
    {191, 8,1,1, 5,1,1},
    {192, 8,224,1, 8,224,1},
    {193, 224,1,1, 140,1,1},
    {194, 8,32,1, 8,32,1},
    {195, 8,1,1, 5,1,1},
    {196, 8,48,1, 8,48,1},
    {197, 80,1,1, 50,1,1},
    {198, 8,1,1, 5,1,1},
    {199, 64,1,1, 40,1,1},
    {200, 1,4,64, 1,6,40},
    {201, 64,1,1, 40,1,1},
    {202, 64,1,1, 40,1,1},
    {203, 8,32,1, 8,32,1},
    {204, 8,1,1, 5,1,1},
    {205, 8,224,1, 8,224,1},
    {206, 224,1,1, 140,1,1},
    {207, 8,32,1, 8,32,1},
    {208, 8,1,1, 5,1,1},
    {209, 8,48,1, 8,48,1},
    {210, 80,1,1, 50,1,1},
    {211, 8,1,1, 5,1,1},
    {212, 64,1,1, 40,1,1},
    {213, 1,4,64, 1,6,40},
    {214, 64,1,1, 40,1,1},
    {215, 64,1,1, 40,1,1},
    {216, 8,32,1, 8,32,1},
    {217, 8,1,1, 5,1,1},
    {218, 8,224,1, 8,224,1},
    {219, 224,1,1, 140,1,1},
    {220, 8,32,1, 8,32,1},
    {221, 8,1,1, 5,1,1},
    {222, 8,48,1, 8,48,1},
    {223, 80,1,1, 50,1,1},
    {224, 8,1,1, 5,1,1},
    {225, 64,1,1, 40,1,1},
    {226, 1,4,64, 1,6,40},
    {227, 64,1,1, 40,1,1},
    {228, 64,1,1, 40,1,1},
    {229, 8,32,1, 8,32,1},
    {230, 8,1,1, 5,1,1},
    {231, 8,224,1, 8,224,1},
    {232, 224,1,1, 140,1,1},
    {233, 8,32,1, 8,32,1},
    {234, 8,1,1, 5,1,1},
    {235, 8,48,1, 8,48,1},
    {236, 80,1,1, 50,1,1},
    {237, 8,1,1, 5,1,1},
    {238, 64,1,1, 40,1,1},
    {239, 1,4,64, 1,6,40},
    {240, 64,1,1, 40,1,1},
    {241, 64,1,1, 40,1,1},
    {242, 8,32,1, 8,32,1},
    {243, 8,1,1, 5,1,1},
    {244, 8,224,1, 8,224,1},
    {245, 224,1,1, 140,1,1},
    {246, 8,32,1, 8,32,1},
    {247, 8,1,1, 5,1,1},
    {248, 8,48,1, 8,48,1},
    {249, 80,1,1, 50,1,1},
    {250, 8,1,1, 5,1,1},
    {251, 64,1,1, 40,1,1},
    {252, 1,4,64, 1,6,40},
    {253, 64,1,1, 40,1,1},
    {254, 64,1,1, 40,1,1},
    {255, 8,32,1, 8,32,1},
    {256, 8,1,1, 5,1,1},
    {257, 8,224,1, 8,224,1},
    {258, 224,1,1, 140,1,1},
    {259, 8,32,1, 8,32,1},
    {260, 8,1,1, 5,1,1},
    {261, 8,48,1, 8,48,1},
    {262, 80,1,1, 50,1,1},
    {263, 8,1,1, 5,1,1},
    {264, 64,1,1, 40,1,1},
    {265, 1,4,64, 1,6,40},
    {266, 64,1,1, 40,1,1},
    {267, 64,1,1, 40,1,1},
    {268, 8,32,1, 8,32,1},
    {269, 8,1,1, 5,1,1},
    {270, 8,224,1, 8,224,1},
    {271, 224,1,1, 140,1,1},
    {272, 8,32,1, 8,32,1},
    {273, 8,1,1, 5,1,1},
    {274, 8,48,1, 8,48,1},
    {275, 80,1,1, 50,1,1},
    {276, 8,1,1, 5,1,1},
    {277, 64,1,1, 40,1,1},
    {278, 1,4,64, 1,6,40},
    {279, 64,1,1, 40,1,1},
    {280, 64,1,1, 40,1,1},
    {281, 8,32,1, 8,32,1},
    {282, 8,1,1, 5,1,1},
    {283, 8,224,1, 8,224,1},
    {284, 224,1,1, 140,1,1},
    {285, 8,32,1, 8,32,1},
    {286, 8,1,1, 5,1,1},
    {287, 8,48,1, 8,48,1},
    {288, 80,1,1, 50,1,1},
    {289, 8,1,1, 5,1,1},
    {290, 64,1,1, 40,1,1},
    {291, 1,4,64, 1,6,40},
    {292, 64,1,1, 40,1,1},
    {293, 64,1,1, 40,1,1},
    {294, 8,32,1, 8,32,1},
    {295, 8,1,1, 5,1,1},
    {296, 8,224,1, 8,224,1},
    {297, 224,1,1, 140,1,1},
    {298, 8,32,1, 8,32,1},
    {299, 8,1,1, 5,1,1},
    {300, 8,48,1, 8,48,1},
    {301, 80,1,1, 50,1,1},
    {302, 8,1,1, 5,1,1},
    {303, 64,1,1, 40,1,1},
    {304, 1,4,64, 1,6,40},
    {305, 64,1,1, 40,1,1},
    {306, 64,1,1, 40,1,1},
    {307, 8,32,1, 8,32,1},
    {308, 8,1,1, 5,1,1},
    {309, 8,224,1, 8,224,1},
    {310, 224,1,1, 140,1,1},
    {311, 8,32,1, 8,32,1},
    {312, 8,1,1, 5,1,1},
    {313, 8,48,1, 8,48,1},
    {314, 80,1,1, 50,1,1},
    {315, 8,1,1, 5,1,1},
    {316, 64,1,1, 40,1,1},
    {317, 1,4,64, 1,6,40},
    {318, 64,1,1, 40,1,1},
    {319, 64,1,1, 40,1,1},
    {320, 8,32,1, 8,32,1},
    {321, 8,1,1, 5,1,1},
    {322, 8,224,1, 8,224,1},
    {323, 224,1,1, 140,1,1},
    {324, 8,32,1, 8,32,1},
    {325, 8,1,1, 5,1,1},
    {326, 8,48,1, 8,48,1},
    {327, 80,1,1, 50,1,1},
    {328, 8,1,1, 5,1,1},
    {329, 64,1,1, 40,1,1},
    {330, 1,4,64, 1,6,40},
    {331, 64,1,1, 40,1,1},
    {332, 64,1,1, 40,1,1},
    {333, 8,32,1, 8,32,1},
    {334, 8,1,1, 5,1,1},
    {335, 8,224,1, 8,224,1},
    {336, 224,1,1, 140,1,1},
    {337, 8,32,1, 8,32,1},
    {338, 8,1,1, 5,1,1},
    {339, 8,48,1, 8,48,1},
    {340, 80,1,1, 50,1,1},
    {341, 8,1,1, 5,1,1},
    {342, 64,1,1, 40,1,1},
    {343, 1,4,64, 1,6,40},
    {344, 64,1,1, 40,1,1},
    {345, 64,1,1, 40,1,1},
    {346, 8,32,1, 8,32,1},
    {347, 8,1,1, 5,1,1},
    {348, 8,224,1, 8,224,1},
    {349, 224,1,1, 140,1,1},
    {350, 8,32,1, 8,32,1},
    {351, 8,1,1, 5,1,1},
    {352, 8,48,1, 8,48,1},
    {353, 80,1,1, 50,1,1},
    {354, 8,1,1, 5,1,1},
    {355, 64,1,1, 40,1,1},
    {356, 1,4,64, 1,6,40},
    {357, 64,1,1, 40,1,1},
    {358, 64,1,1, 40,1,1},
    {359, 8,32,1, 8,32,1},
    {360, 8,1,1, 5,1,1},
    {361, 8,224,1, 8,224,1},
    {362, 224,1,1, 140,1,1},
    {363, 8,32,1, 8,32,1},
    {364, 8,1,1, 5,1,1},
    {365, 8,48,1, 8,48,1},
    {366, 80,1,1, 50,1,1},
    {367, 8,1,1, 5,1,1},
    {368, 64,1,1, 40,1,1},
    {369, 1,4,64, 1,6,40},
    {370, 64,1,1, 40,1,1},
    {371, 64,1,1, 40,1,1},
    {372, 8,32,1, 8,32,1},
    {373, 8,1,1, 5,1,1},
    {374, 8,224,1, 8,224,1},
    {375, 224,1,1, 140,1,1},
    {376, 8,32,1, 8,32,1},
    {377, 8,1,1, 5,1,1},
    {378, 8,48,1, 8,48,1},
    {379, 80,1,1, 50,1,1},
    {380, 8,1,1, 5,1,1},
    {381, 64,1,1, 40,1,1},
    {382, 1,4,64, 1,6,40},
    {383, 64,1,1, 40,1,1},
    {384, 64,1,1, 40,1,1},
    {385, 8,32,1, 8,32,1},
    {386, 8,1,1, 5,1,1},
    {387, 8,224,1, 8,224,1},
    {388, 224,1,1, 140,1,1},
    {389, 8,32,1, 8,32,1},
    {390, 8,1,1, 5,1,1},
    {391, 8,48,1, 8,48,1},
    {392, 80,1,1, 50,1,1},
    {393, 8,1,1, 5,1,1},
    {394, 64,1,1, 40,1,1},
    {395, 1,4,64, 1,6,40},
    {396, 64,1,1, 40,1,1},
    {397, 64,1,1, 40,1,1},
    {398, 8,32,1, 8,32,1},
    {399, 8,1,1, 5,1,1},
    {400, 8,224,1, 8,224,1},
    {401, 224,1,1, 140,1,1},
    {402, 8,32,1, 8,32,1},
    {403, 8,1,1, 5,1,1},
    {404, 8,48,1, 8,48,1},
    {405, 80,1,1, 50,1,1},
    {406, 8,1,1, 5,1,1},
    {407, 64,1,1, 40,1,1},
    {408, 1,4,64, 1,6,40},
    {409, 64,1,1, 40,1,1},
    {410, 64,1,1, 40,1,1},
    {411, 8,32,1, 8,32,1},
    {412, 8,1,1, 5,1,1},
    {413, 8,224,1, 8,224,1},
    {414, 224,1,1, 140,1,1},
    {415, 8,32,1, 8,32,1},
    {416, 8,1,1, 5,1,1}
};
int NUM_NODE_MAPPINGS_8_TO_5 = sizeof(NODE_GRID_MAP_8_TO_5) / sizeof(NODE_GRID_MAP_8_TO_5[0]);

/*
 * Node 정보 상세 디버그 함수
 * cudaGraphKernelNodeGetParams 실패 시 대체 정보 수집
 */
std::string debug_node_info(cudaGraphNode_t node, size_t node_idx) {
    std::stringstream ss;
    
    ss << "\n[DEBUG Node " << node_idx << "]\n";
    ss << "  Node Handle: " << std::hex << reinterpret_cast<uintptr_t>(node) << std::dec << "\n";
    
    // 1. Node Type 확인
    cudaGraphNodeType type;
    cudaError_t err = cudaGraphNodeGetType(node, &type);
    if (err == cudaSuccess) {
        ss << "  Type: " << node_type_to_string(type) << " (" << static_cast<int>(type) << ")\n";
    } else {
        ss << "  Type: ERROR - " << cudaGetErrorString(err) << "\n";
        cudaGetLastError();
    }
    
    // 2. Kernel params 재시도 (더 자세한 에러 정보)
    if (type == cudaGraphNodeTypeKernel) {
        cudaKernelNodeParams params;
        memset(&params, 0, sizeof(params));
        
        err = cudaGraphKernelNodeGetParams(node, &params);
        if (err == cudaSuccess) {
            ss << "  ✓ Kernel Params Retrieved:\n";
            ss << "    Grid: (" << params.gridDim.x << ", " << params.gridDim.y << ", " << params.gridDim.z << ")\n";
            ss << "    Block: (" << params.blockDim.x << ", " << params.blockDim.y << ", " << params.blockDim.z << ")\n";
            ss << "    Shared Memory: " << params.sharedMemBytes << " bytes\n";
            ss << "    Function Ptr: " << std::hex << reinterpret_cast<uintptr_t>(params.func) << std::dec << "\n";
            ss << "  Raw Node Memory Dump (first 128 bytes):\n";
            unsigned int* node_bytes = reinterpret_cast<unsigned int*>(node);
            for (int i = 0; i < 128; i += 1) {
                ss << "[" << std::setw(4) << i << "]"  << std::setw(2) << static_cast<unsigned int>(node_bytes[i]) << " ";
                ss << std::dec << "\n";
            }
        } else {
            ss << "  ✗ Kernel Params FAILED: " << cudaGetErrorString(err) << " (error code: " << err << ")\n";
            cudaGetLastError();
            
            // 5. Node handle 메모리 직접 덤프 (매우 위험하지만 디버깅용)
            ss << "  Raw Node Memory Dump (first 128 bytes):\n";
            unsigned int* node_bytes = reinterpret_cast<unsigned int*>(node);
            for (int i = 0; i < 128; i += 1) {
                ss << "[" << std::setw(4) << i << "]"  << std::setw(2) << static_cast<unsigned int>(node_bytes[i]) << " ";
                ss << std::dec << "\n";
            }
        }
    }
    
    return ss.str();
}

std::string all_node_debug_graph(
    py::object input_obj, 
    const std::string& filename
) {
    std::stringstream ss;
    std::stringstream node_debug_ss;
    ss << "========================================\n";
    ss << "Target Model: meta-llama/Llama-3.1-8B-Instruct\n";
    ss << "========================================\n";

    // 1. 디바이스 동기화 및 에러 초기화
    cudaDeviceSynchronize(); 
    cudaError_t prior_err = cudaGetLastError();
    if (prior_err != cudaSuccess) {
        ss << "[Warning] Cleared prior CUDA error: " << cudaGetErrorString(prior_err) << "\n";
    }

    // 2. 그래프 핸들 추출
    cudaGraph_t graph = nullptr;
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
    } else if (py::isinstance<py::int_>(input_obj)) {
        graph = reinterpret_cast<cudaGraph_t>(input_obj.cast<uint64_t>());
    } else {
        return "Error: Input must be PyCapsule or int";
    }

    if (graph == nullptr) return "Error: Invalid graph pointer";

    // 3. 노드 가져오기
    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    if (err != cudaSuccess) return "CUDA Error: " + std::string(cudaGetErrorString(err));

    std::vector<cudaGraphNode_t> nodes(numNodes);
    cudaGraphGetNodes(graph, nodes.data(), &numNodes);

    // 4. 노드 순회 및 수정
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        if (cudaGraphNodeGetType(nodes[i], &type) != cudaSuccess) continue;
        // 디버그 정보 수집
        node_debug_ss << debug_node_info(nodes[i], i);
    }

    // 5. 결과 저장 (선택)
    if (!filename.empty()) {
        cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE);
    }
    try{
        std::string debug_filename = filename + "_node_debug.txt";
        std::ofstream debug_file(debug_filename);
        debug_file << node_debug_ss.str();
        debug_file.close();
        ss << "Node debug info saved to: " << debug_filename << "\n";
    } catch (const std::exception& e) {
        ss << "Node debug save failed: " << e.what() << "\n";
    }
    // 종료 전 정리
    cudaDeviceSynchronize();
    cudaGetLastError();

    return ss.str();
}

std::string manipulation_Llama_3_1_8B_Instruct_graph(
    py::object input_obj, 
    const int original_batch, 
    const int new_batch, 
    const std::string& filename
) {
    std::stringstream ss;
    std::stringstream node_debug_ss;
    ss << "========================================\n";
    ss << "Target Model: meta-llama/Llama-3.1-8B-Instruct\n";
    ss << "Manipulation: Batch " << original_batch << " -> " << new_batch << "\n";
    ss << "========================================\n";

    // 비율 계산
    float batch_ratio = static_cast<float>(new_batch) / static_cast<float>(original_batch);
    ss << "Batch Scale Ratio: " << batch_ratio << "\n";

    // 1. 디바이스 동기화 및 에러 초기화
    cudaDeviceSynchronize(); 
    cudaError_t prior_err = cudaGetLastError();
    if (prior_err != cudaSuccess) {
        ss << "[Warning] Cleared prior CUDA error: " << cudaGetErrorString(prior_err) << "\n";
    }

    // 2. 그래프 핸들 추출
    cudaGraph_t graph = nullptr;
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
    } else if (py::isinstance<py::int_>(input_obj)) {
        graph = reinterpret_cast<cudaGraph_t>(input_obj.cast<uint64_t>());
    } else {
        return "Error: Input must be PyCapsule or int";
    }

    if (graph == nullptr) return "Error: Invalid graph pointer";

    // 3. 노드 가져오기
    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    if (err != cudaSuccess) return "CUDA Error: " + std::string(cudaGetErrorString(err));

    std::vector<cudaGraphNode_t> nodes(numNodes);
    cudaGraphGetNodes(graph, nodes.data(), &numNodes);

    int modified_count = 0;

    // 4. 노드 순회 및 수정
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        if (cudaGraphNodeGetType(nodes[i], &type) != cudaSuccess) continue;

        // 디버그 정보 수집
        node_debug_ss << debug_node_info(nodes[i], i);

        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            // 중요: memset으로 0 초기화 필수 (안하면 쓰레기값 들어감)
            memset(&params, 0, sizeof(params));
            
            err = cudaGraphKernelNodeGetParams(nodes[i], &params);
            bool using_raw_data = false;
            
            if (err != cudaSuccess) {
                // cudaGraphKernelNodeGetParams 실패 시 raw node data에서 grid/block 정보 추출
                // raw data 구조: [10,11,12] = grid.x,y,z / [13,14,15] = block.x,y,z
                unsigned int* node_raw = reinterpret_cast<unsigned int*>(nodes[i]);
                
                params.gridDim.x = node_raw[10];
                params.gridDim.y = node_raw[11];
                params.gridDim.z = node_raw[12];
                params.blockDim.x = node_raw[13];
                params.blockDim.y = node_raw[14];
                params.blockDim.z = node_raw[15];
                
                using_raw_data = true;
                cudaGetLastError(); // 에러 클리어
            }
            dim3 orig_grid = params.gridDim;
            dim3 new_grid = orig_grid;
            bool is_modified = false;

            // [Table-based Mapping] NODE_GRID_MAP_16_TO_9 사용
            // 배치 16->9 변환인 경우 테이블 조회
            int mod = i % 13;
            if (mod == 0 || mod == 3 || mod == 9)
            {
                new_grid.x = new_batch;
                new_grid.y = 1;
                new_grid.z = 1;
                is_modified = true;
            }
            else if (mod == 4 || mod == 6 || mod == 7)
            {
                new_grid.x = new_batch * 8;
                new_grid.y = 1;
                new_grid.z = 1;
                is_modified = true;
            }
            else{
                ss << "  Node " << i << ": No modification rule applied.\n";
                continue;
            }
            // 수정 적용
            if (is_modified) {
                // Raw data 사용 시 직접 메모리에 쓰기
                if (using_raw_data) {
                    unsigned int* node_raw = reinterpret_cast<unsigned int*>(nodes[i]);
                    node_raw[10] = new_grid.x;
                    node_raw[11] = new_grid.y;
                    node_raw[12] = new_grid.z;
                    
                    ss << "  Node " << i << ": Grid (" 
                       << orig_grid.x << ", " << orig_grid.y << ", " << orig_grid.z << ") -> ("
                       << new_grid.x << ", " << new_grid.y << ", " << new_grid.z << ")\n";
                    modified_count++;
                } else {
                    // 일반적인 경우 cudaGraphKernelNodeSetParams 사용
                    params.gridDim = new_grid;
                    err = cudaGraphKernelNodeSetParams(nodes[i], &params);
                    if (err == cudaSuccess) {
                        ss << "  Node " << i << ": Grid (" 
                           << orig_grid.x << ", " << orig_grid.y << ", " << orig_grid.z << ") -> ("
                           << new_grid.x << ", " << new_grid.y << ", " << new_grid.z << ")\n";
                        modified_count++;
                    } else {
                        ss << "  Node " << i << ": Failed update: " << cudaGetErrorString(err) << "\n";
                    }
                }
            }
        }
    }

    // 5. 결과 저장 (선택)
    if (!filename.empty()) {
        cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE);
    }
    try{
        std::string debug_filename = filename + "_node_debug.txt";
        std::ofstream debug_file(debug_filename);
        debug_file << node_debug_ss.str();
        debug_file.close();
        ss << "Node debug info saved to: " << debug_filename << "\n";
    } catch (const std::exception& e) {
        ss << "Node debug save failed: " << e.what() << "\n";
    }
    ss << "----------------------------------------\n";
    ss << "Modified: " << modified_count << " nodes\n";
    ss << "========================================\n";

    // 종료 전 정리
    cudaDeviceSynchronize();
    cudaGetLastError();

    return ss.str();
}

std::string manipulation_huggingface_graph(
    py::object input_obj,
    const int batch,
    const std::string& filename,
    const bool apply_block
) {
    std::stringstream ss;

    ss << "========================================\n";
    ss << "PyTorch CUDA Graph Manipulation (file-based)\n";
    ss << "Batch: " << batch << "\n";
    ss << "========================================\n";

    cudaDeviceSynchronize();
    cudaError_t prior_err = cudaGetLastError();
    if (prior_err != cudaSuccess) {
        ss << "[Warning] Cleared prior CUDA error: " << cudaGetErrorString(prior_err) << "\n";
    }

    cudaGraph_t graph = nullptr;
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
        ss << "Input Type: PyCapsule\n";
    } else if (py::isinstance<py::int_>(input_obj)) {
        uint64_t ptr_val = input_obj.cast<uint64_t>();
        graph = reinterpret_cast<cudaGraph_t>(ptr_val);
        ss << "Input Type: Integer (Address: " << ptr_val << ")\n";
    } else {
        return "Error: Input must be PyCapsule or int";
    }

    if (graph == nullptr) {
        return "Error: Invalid graph pointer (nullptr)";
    }

    std::string parse_path = "cuda_graphs/parse_currunt_llama3_8b_bs_" + std::to_string(batch) + "_graph.dot.txt";
    std::ifstream in(parse_path);
    if (!in.good()) {
        return "Error: Could not open parse file: " + parse_path;
    }

    struct NodeDims {
        unsigned int gx, gy, gz;
        unsigned int bx, by, bz;
    };

    std::unordered_map<int, NodeDims> node_map;
    std::string line;
    while (std::getline(in, line)) {
        int node_id = -1;
        unsigned int gx = 0, gy = 0, gz = 0, bx = 0, by = 0, bz = 0, shared = 0;
        int matched = std::sscanf(
            line.c_str(),
            "Node %d: Grid (%u,%u,%u), Block (%u,%u,%u) shared: %u",
            &node_id, &gx, &gy, &gz, &bx, &by, &bz, &shared
        );
        if (matched == 8 && node_id >= 0) {
            node_map[node_id] = {gx, gy, gz, bx, by, bz};
        }
    }

    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    if (err != cudaSuccess) {
        return "CUDA Error (cudaGraphGetNodes): " + std::string(cudaGetErrorString(err));
    }

    std::vector<cudaGraphNode_t> nodes(numNodes);
    err = cudaGraphGetNodes(graph, nodes.data(), &numNodes);
    if (err != cudaSuccess) {
        return "CUDA Error (get node list): " + std::string(cudaGetErrorString(err));
    }

    int modified_count = 0;
    int missing_count = 0;

    for (size_t i = 0; i < numNodes; i++) {
        if (i < 24){
            missing_count++;
            ss << "  Node " << i << ": Skipped modification for initial nodes.\n";
            continue;
        }

        if (i % 50 == 1){
            missing_count++;
            ss << "  Node " << i << ": Skipped modification for initial nodes.\n";
            continue;
        }
            
        auto it = node_map.find(static_cast<int>(i));
        if (it == node_map.end()) {
            missing_count++;
            continue;
        }

        cudaGraphNodeType type;
        if (cudaGraphNodeGetType(nodes[i], &type) != cudaSuccess) continue;
        if (type != cudaGraphNodeTypeKernel) continue;

        cudaKernelNodeParams params;
        cudaKernelNodeParams orig_params;
        memset(&params, 0, sizeof(params));
        err = cudaGraphKernelNodeGetParams(nodes[i], &params);
        bool using_raw_data = false;
        if (err != cudaSuccess) {
            unsigned int* node_raw = reinterpret_cast<unsigned int*>(nodes[i]);
            params.gridDim.x = node_raw[10];
            params.gridDim.y = node_raw[11];
            params.gridDim.z = node_raw[12];
            params.blockDim.x = node_raw[13];
            params.blockDim.y = node_raw[14];
            params.blockDim.z = node_raw[15];
            using_raw_data = true;
            cudaGetLastError();
        }
        orig_params.gridDim = params.gridDim;
        orig_params.blockDim = params.blockDim;

        params.gridDim.x = it->second.gx;
        params.gridDim.y = it->second.gy;
        params.gridDim.z = it->second.gz;
        
        if (apply_block) {
            params.blockDim.x = it->second.bx;
            params.blockDim.y = it->second.by;
            params.blockDim.z = it->second.bz;
        }

        if (using_raw_data) {
            unsigned int* node_raw = reinterpret_cast<unsigned int*>(nodes[i]);
            node_raw[10] = params.gridDim.x;
            node_raw[11] = params.gridDim.y;
            node_raw[12] = params.gridDim.z;
            if (apply_block) {
                node_raw[13] = params.blockDim.x;
                node_raw[14] = params.blockDim.y;
                node_raw[15] = params.blockDim.z;
            }
            modified_count++;
            // print modified information
            ss << "  Node " << i << " Raw : Grid (" 
               << orig_params.gridDim.x << ", " << orig_params.gridDim.y << ", " << orig_params.gridDim.z << ") -> (" << params.gridDim.x << ", " << params.gridDim.y << ", " << params.gridDim.z << "), Block ("
               << orig_params.blockDim.x << ", " << orig_params.blockDim.y << ", " << orig_params.blockDim.z << ") -> (" << params.blockDim.x << ", " << params.blockDim.y << ", " << params.blockDim.z << ")\n";
        } else {
            err = cudaGraphKernelNodeSetParams(nodes[i], &params);
            ss << "  Node " << i << ": Grid (" 
               << orig_params.gridDim.x << ", " << orig_params.gridDim.y << ", " << orig_params.gridDim.z << ") -> (" << params.gridDim.x << ", " << params.gridDim.y << ", " << params.gridDim.z << "), Block ("
               << orig_params.blockDim.x << ", " << orig_params.blockDim.y << ", " << orig_params.blockDim.z << ") -> (" << params.blockDim.x << ", " << params.blockDim.y << ", " << params.blockDim.z << ")\n";
            if (err == cudaSuccess) {
                modified_count++;
            } else {
                ss << "  Node " << i << ": Failed update: " << cudaGetErrorString(err) << "\n";
            }
        }
    }

    if (!filename.empty()) {
        cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE);
    }

    ss << "Modified: " << modified_count << " kernel nodes\n";
    ss << "Missing mappings: " << missing_count << " nodes\n";
    ss << "========================================\n";

    cudaDeviceSynchronize();
    cudaGetLastError();

    return ss.str();
}

std::string manipulation_pytorch_graph(py::object input_obj, const int original_batch, const int new_batch, const std::string& filename) {
    std::stringstream ss;

    ss << "========================================\n";
    ss << "PyTorch CUDA Graph Manipulation: " << original_batch << " -> " << new_batch << "\n";
    ss << "========================================\n";

    float batch_ratio = static_cast<float>(new_batch) / static_cast<float>(original_batch);

    // [핵심 수정 1] 진입 전 디바이스 동기화 및 기존 에러 클리어
    // 이전 단계(debug_dump 등)에서 발생한 비동기 에러가 있다면 여기서 잡아서 리셋합니다.
    cudaDeviceSynchronize(); 
    cudaError_t prior_err = cudaGetLastError();
    if (prior_err != cudaSuccess) {
        ss << "[Warning] Found and cleared prior CUDA error: " << cudaGetErrorString(prior_err) << "\n";
    }

    cudaGraph_t graph = nullptr;

    // Case 1: PyCapsule (구버전 호환)
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
        ss << "Input Type: PyCapsule\n";
    } 
    // Case 2: Integer (현재 PyTorch 버전)
    else if (py::isinstance<py::int_>(input_obj)) {
        uint64_t ptr_val = input_obj.cast<uint64_t>();
        graph = reinterpret_cast<cudaGraph_t>(ptr_val);
        ss << "Input Type: Integer (Address: " << ptr_val << ")\n";
    }
    else {
        return "Error: Expected PyCapsule or int, got " + std::string(py::str(input_obj.get_type()));
    }

    if (graph == nullptr) {
        return "Error: Invalid graph pointer (nullptr)";
    }

    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    
    if (err != cudaSuccess) {
        // 여기서 에러가 난다면 진짜 핸들 문제거나 심각한 드라이버 오류입니다.
        return "CUDA Error (cudaGraphGetNodes): " + std::string(cudaGetErrorString(err));
    }

    std::vector<cudaGraphNode_t> nodes(numNodes);
    err = cudaGraphGetNodes(graph, nodes.data(), &numNodes);
    if (err != cudaSuccess) {
        return "CUDA Error (get node list): " + std::string(cudaGetErrorString(err));
    }

    int kernel_count = 0;
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        err = cudaGraphNodeGetType(nodes[i], &type);
        if (err != cudaSuccess) continue;

        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            memset(&params, 0, sizeof(params));
            err = cudaGraphKernelNodeGetParams(nodes[i], &params);

            dim3 orig_grid = params.gridDim;

            if (err == cudaSuccess) {
                
                params.gridDim.x = static_cast<unsigned int>(orig_grid.x * batch_ratio);
                err = cudaGraphKernelNodeSetParams(nodes[i], &params);
                if (err != cudaSuccess) {
                    ss << "  Node " << i << ": Failed to set params: " << cudaGetErrorString(err) << "\n";
                } else {
                    ss << "  Node " << i << ": Grid (" << orig_grid.x << ", " 
                       << orig_grid.y << ", " << orig_grid.z << ") -> ("
                       << params.gridDim.x << ", " 
                       << params.gridDim.y << ", " << params.gridDim.z << ")\n";
                }
            } else {
                ss << "  Node " << i << ": KERNEL (params unavailable)\n";
                kernel_count++;
                // 에러 클리어 - 다음 노드 진행을 위해
                cudaGetLastError();
            }

        }
    }

    try{
        CUDA_CHECK(cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE));
    } catch (const std::exception& e) {
        ss << "DOT save failed: "<< filename << ": " << e.what() << "\n";
    }

    ss << "  Total Kernel Nodes: " << kernel_count << "\n";
    ss << "========================================\n";
    
    // [중요] 함수 종료 전 모든 에러 상태 클리어
    cudaDeviceSynchronize();
    cudaGetLastError();  // 에러 상태 리셋
    
    return ss.str();
}

std::string cuda_graph_debug_print(py::object input_obj, const std::string& filename) {
    std::stringstream ss;

    ss << "========================================\n";
    ss << "PyTorch CUDA Graph Debug Print\n";
    ss << "========================================\n";

    // [핵심 수정 1] 진입 전 디바이스 동기화 및 기존 에러 클리어
    // 이전 단계(debug_dump 등)에서 발생한 비동기 에러가 있다면 여기서 잡아서 리셋합니다.
    cudaDeviceSynchronize(); 
    cudaError_t prior_err = cudaGetLastError();
    if (prior_err != cudaSuccess) {
        ss << "[Warning] Found and cleared prior CUDA error: " << cudaGetErrorString(prior_err) << "\n";
    }

    cudaGraph_t graph = nullptr;

    // Case 1: PyCapsule (구버전 호환)
    if (PyCapsule_CheckExact(input_obj.ptr())) {
        graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(input_obj.ptr(), nullptr));
        ss << "Input Type: PyCapsule\n";
    } 
    // Case 2: Integer (현재 PyTorch 버전)
    else if (py::isinstance<py::int_>(input_obj)) {
        uint64_t ptr_val = input_obj.cast<uint64_t>();
        graph = reinterpret_cast<cudaGraph_t>(ptr_val);
        ss << "Input Type: Integer (Address: " << ptr_val << ")\n";
    }
    else {
        return "Error: Expected PyCapsule or int, got " + std::string(py::str(input_obj.get_type()));
    }

    if (graph == nullptr) {
        return "Error: Invalid graph pointer (nullptr)";
    }

    try{
        CUDA_CHECK(cudaGraphDebugDotPrint(graph, filename.c_str(), DOT_FLAGS_VERBOSE));
    } catch (const std::exception& e) {
        ss << "DOT save failed: "<< filename << ": " << e.what() << "\n";
    }

    size_t numNodes = 0;
    cudaError_t err = cudaGraphGetNodes(graph, nullptr, &numNodes);
    
    if (err != cudaSuccess) {
        // 여기서 에러가 난다면 진짜 핸들 문제거나 심각한 드라이버 오류입니다.
        return "CUDA Error (cudaGraphGetNodes): " + std::string(cudaGetErrorString(err));
    }

    std::vector<cudaGraphNode_t> nodes(numNodes);
    err = cudaGraphGetNodes(graph, nodes.data(), &numNodes);
    if (err != cudaSuccess) {
        return "CUDA Error (get node list): " + std::string(cudaGetErrorString(err));
    }

    int kernel_count = 0;
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        err = cudaGraphNodeGetType(nodes[i], &type);
        if (err != cudaSuccess) continue;

        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            memset(&params, 0, sizeof(params));
            err = cudaGraphKernelNodeGetParams(nodes[i], &params);
            if (err == cudaSuccess) {
                ss << "  Node " << i << ": Grid (" << params.gridDim.x << ", " 
                   << params.gridDim.y << ", " << params.gridDim.z << ")\n";
                kernel_count++;
            } else {
                ss << "  Node " << i << ": KERNEL (params unavailable)\n";
                kernel_count++;
                // 에러 클리어 - 다음 노드 진행을 위해
                cudaGetLastError();
            }
        }
    }
    
    ss << "  Total Kernel Nodes: " << kernel_count << "\n";
    ss << "========================================\n";
    
    // [중요] 함수 종료 전 모든 에러 상태 클리어
    cudaDeviceSynchronize();
    cudaGetLastError();  // 에러 상태 리셋
    
    return ss.str();
}


// ============================================================
// 그래프 노드 조작 기능
// ============================================================



/*
 * 그래프 노드 정보를 딕셔너리 리스트로 반환
 */
py::list get_graph_nodes_info(py::object graph_capsule) {
    py::list nodes_info;
    
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        throw std::runtime_error("Expected a PyCapsule object");
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        throw std::runtime_error("Could not extract cudaGraph_t from capsule");
    }
    
    size_t numNodes;
    CUDA_CHECK(cudaGraphGetNodes(graph, nullptr, &numNodes));
    
    std::vector<cudaGraphNode_t> nodes(numNodes);
    CUDA_CHECK(cudaGraphGetNodes(graph, nodes.data(), &numNodes));
    
    for (size_t i = 0; i < numNodes; i++) {
        py::dict node_info;
        node_info["index"] = i;
        
        cudaGraphNodeType type;
        CUDA_CHECK(cudaGraphNodeGetType(nodes[i], &type));
        node_info["type"] = node_type_to_string(type);
        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            CUDA_CHECK(cudaGraphKernelNodeGetParams(nodes[i], &params));
            
            py::dict grid;
            grid["x"] = params.gridDim.x;
            grid["y"] = params.gridDim.y;
            grid["z"] = params.gridDim.z;
            node_info["grid"] = grid;
            
            py::dict block;
            block["x"] = params.blockDim.x;
            block["y"] = params.blockDim.y;
            block["z"] = params.blockDim.z;
            node_info["block"] = block;
            
            node_info["shared_memory"] = params.sharedMemBytes;
            node_info["func_ptr"] = reinterpret_cast<uint64_t>(params.func);
            
        } else if (type == cudaGraphNodeTypeMemcpy) {
            cudaMemcpy3DParms memcpyParams = {0};
            CUDA_CHECK(cudaGraphMemcpyNodeGetParams(nodes[i], &memcpyParams));
            
            std::string kind;
            switch (memcpyParams.kind) {
                case cudaMemcpyHostToDevice: kind = "HostToDevice"; break;
                case cudaMemcpyDeviceToHost: kind = "DeviceToHost"; break;
                case cudaMemcpyDeviceToDevice: kind = "DeviceToDevice"; break;
                default: kind = "Other"; break;
            }
            node_info["memcpy_kind"] = kind;
            
            py::dict extent;
            extent["width"] = memcpyParams.extent.width;
            extent["height"] = memcpyParams.extent.height;
            extent["depth"] = memcpyParams.extent.depth;
            node_info["extent"] = extent;
            
        } else if (type == cudaGraphNodeTypeMemset) {
            cudaMemsetParams memsetParams;
            CUDA_CHECK(cudaGraphMemsetNodeGetParams(nodes[i], &memsetParams));
            
            node_info["value"] = memsetParams.value;
            node_info["width"] = memsetParams.width;
            node_info["height"] = memsetParams.height;
        }
        
        nodes_info.append(node_info);
    }
    
    return nodes_info;
}

/*
 * 그래프의 커널 노드 Grid dimension 수정
 */
bool modify_kernel_node_grid(
    py::object graph_capsule,
    int node_index,
    int grid_x, int grid_y, int grid_z
) {
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        throw std::runtime_error("Expected a PyCapsule object");
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        throw std::runtime_error("Could not extract cudaGraph_t from capsule");
    }
    
    size_t numNodes;
    CUDA_CHECK(cudaGraphGetNodes(graph, nullptr, &numNodes));
    
    if (node_index < 0 || node_index >= static_cast<int>(numNodes)) {
        throw std::runtime_error("Node index out of range");
    }
    
    std::vector<cudaGraphNode_t> nodes(numNodes);
    CUDA_CHECK(cudaGraphGetNodes(graph, nodes.data(), &numNodes));
    
    cudaGraphNodeType type;
    CUDA_CHECK(cudaGraphNodeGetType(nodes[node_index], &type));
    
    if (type != cudaGraphNodeTypeKernel) {
        throw std::runtime_error("Node is not a kernel node");
    }
    
    cudaKernelNodeParams params;
    CUDA_CHECK(cudaGraphKernelNodeGetParams(nodes[node_index], &params));
    
    if (grid_x >= 0) params.gridDim.x = grid_x;
    if (grid_y >= 0) params.gridDim.y = grid_y;
    if (grid_z >= 0) params.gridDim.z = grid_z;
    
    CUDA_CHECK(cudaGraphKernelNodeSetParams(nodes[node_index], &params));
    
    return true;
}

/*
 * Batch 비율에 따라 모든 커널 노드의 Grid dimension 자동 수정
 */
int modify_graph_for_batch(
    py::object graph_capsule,
    int original_batch,
    int new_batch
) {
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        throw std::runtime_error("Expected a PyCapsule object");
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        throw std::runtime_error("Could not extract cudaGraph_t from capsule");
    }
    
    size_t numNodes;
    CUDA_CHECK(cudaGraphGetNodes(graph, nullptr, &numNodes));
    
    std::vector<cudaGraphNode_t> nodes(numNodes);
    CUDA_CHECK(cudaGraphGetNodes(graph, nodes.data(), &numNodes));
    
    float batch_ratio = static_cast<float>(new_batch) / static_cast<float>(original_batch);
    int modified_count = 0;
    
    std::cout << "Modifying graph: Batch " << original_batch << " -> " << new_batch << std::endl;
    std::cout << "Batch ratio: " << batch_ratio << std::endl;
    
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        CUDA_CHECK(cudaGraphNodeGetType(nodes[i], &type));
        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            CUDA_CHECK(cudaGraphKernelNodeGetParams(nodes[i], &params));
            
            dim3 orig_grid = params.gridDim;
            bool modified = false;
            
            // 패턴: batch에 비례하는 차원 스케일링
            if (orig_grid.z > 1 && orig_grid.z == static_cast<unsigned int>(original_batch * 8)) {
                params.gridDim.z = static_cast<unsigned int>(orig_grid.z * batch_ratio);
                modified = true;
            }
            else if (orig_grid.y > 1 && orig_grid.y == static_cast<unsigned int>(original_batch * 2)) {
                params.gridDim.y = static_cast<unsigned int>(orig_grid.y * batch_ratio);
                modified = true;
            }
            else if (orig_grid.x > 1 && orig_grid.y == 1 && orig_grid.z == 1) {
                params.gridDim.x = static_cast<unsigned int>(std::max(1.0f, orig_grid.x * batch_ratio));
                modified = true;
            }
            
            if (modified) {
                CUDA_CHECK(cudaGraphKernelNodeSetParams(nodes[i], &params));
                
                std::cout << "  Node " << i << ": Grid (" 
                          << orig_grid.x << "," << orig_grid.y << "," << orig_grid.z << ") -> ("
                          << params.gridDim.x << "," << params.gridDim.y << "," << params.gridDim.z << ")" << std::endl;
                modified_count++;
            }
        }
    }
    
    std::cout << "Modified " << modified_count << " kernel nodes" << std::endl;
    return modified_count;
}

/*
 * 수정된 그래프를 재인스턴스화
 */
py::object reinstantiate_graph(py::object graph_capsule) {
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        throw std::runtime_error("Expected a PyCapsule object");
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        throw std::runtime_error("Could not extract cudaGraph_t from capsule");
    }
    
    cudaGraphExec_t graphExec;
    CUDA_CHECK(cudaGraphInstantiate(&graphExec, graph, nullptr, nullptr, 0));
    
    return py::capsule(graphExec, [](void* ptr) {
        if (ptr) cudaGraphExecDestroy(static_cast<cudaGraphExec_t>(ptr));
    });
}

/*
 * 그래프 노드 개수 반환
 */
int64_t get_node_count(py::object graph_capsule) {
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        return -1;
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        return -1;
    }
    
    size_t numNodes;
    if (cudaGraphGetNodes(graph, nullptr, &numNodes) != cudaSuccess) {
        return -1;
    }
    
    return static_cast<int64_t>(numNodes);
}

/*
 * 그래프 정보를 문자열로 출력
 */
std::string print_graph_info(py::object graph_capsule) {
    std::stringstream ss;
    
    if (!PyCapsule_CheckExact(graph_capsule.ptr())) {
        return "Error: Not a valid PyCapsule";
    }
    
    cudaGraph_t graph = static_cast<cudaGraph_t>(PyCapsule_GetPointer(graph_capsule.ptr(), nullptr));
    if (graph == nullptr) {
        return "Error: Could not extract cudaGraph_t";
    }
    
    size_t numNodes;
    CUDA_CHECK(cudaGraphGetNodes(graph, nullptr, &numNodes));
    
    std::vector<cudaGraphNode_t> nodes(numNodes);
    CUDA_CHECK(cudaGraphGetNodes(graph, nodes.data(), &numNodes));
    
    ss << "========================================\n";
    ss << "Graph Information\n";
    ss << "Total Nodes: " << numNodes << "\n";
    ss << "========================================\n";
    
    for (size_t i = 0; i < numNodes; i++) {
        cudaGraphNodeType type;
        CUDA_CHECK(cudaGraphNodeGetType(nodes[i], &type));
        
        ss << "\nNode " << i << ": " << node_type_to_string(type) << "\n";
        
        if (type == cudaGraphNodeTypeKernel) {
            cudaKernelNodeParams params;
            CUDA_CHECK(cudaGraphKernelNodeGetParams(nodes[i], &params));
            
            ss << "  Grid: (" << params.gridDim.x << ", " 
               << params.gridDim.y << ", " << params.gridDim.z << ")\n";
            ss << "  Block: (" << params.blockDim.x << ", " 
               << params.blockDim.y << ", " << params.blockDim.z << ")\n";
            ss << "  Shared Memory: " << params.sharedMemBytes << " bytes\n";
        }
    }
    
    ss << "========================================\n";
    return ss.str();
}

// ============================================================
// Python 모듈 정의
// ============================================================
PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
    m.doc() = "CUDA Graph API - DOT file saving and graph manipulation";
    
    // DOT 저장 기능
    m.def("save_graph_dot_from_capsule", &save_graph_dot_from_capsule,
          "Save CUDA graph to DOT file from PyCapsule",
          py::arg("graph_capsule"),
          py::arg("filename"),
          py::arg("flags") = 1u);  // DOT_FLAGS_VERBOSE = 1
    
    m.def("capture_graph_and_save_dot", &capture_graph_and_save_dot,
          "Capture model execution, save DOT file, and return graph handles",
          py::arg("forward_fn"),
          py::arg("input_tensor"),
          py::arg("filename") = "",
          py::arg("flags") = 1u);  // DOT_FLAGS_VERBOSE = 1
    
    m.def("test_empty_graph_dot", &test_empty_graph_dot,
          "Test by creating and saving an empty graph",
          py::arg("filename"));
    
    m.def("save_pytorch_graph_dot", &save_pytorch_graph_dot,
          "Save PyTorch CUDAGraph to DOT file (direct access to at::cuda::CUDAGraph)",
          py::arg("cuda_graph"),
          py::arg("filename"),
          py::arg("flags") = 1u);  // DOT_FLAGS_VERBOSE = 1
    
    m.def("get_pytorch_graph_nodes_info", &get_pytorch_graph_nodes_info,
          "Get node info from PyTorch CUDAGraph",
          py::arg("cuda_graph"));
    
    m.def("print_pytorch_graph_info", &print_pytorch_graph_info,
          "Print basic info of PyTorch CUDAGraph and save DOT file",
          py::arg("cuda_graph"),
          py::arg("filename") = "");
          
    m.def("manipulation_pytorch_graph", &manipulation_pytorch_graph,
    "PyTorch CUDAGraph debug print",
        py::arg("graph_capsule"),
        py::arg("original_batch"),
        py::arg("new_batch"),
        py::arg("filename") = "");

    m.def("all_node_debug_graph", &all_node_debug_graph,
        "PyTorch CUDAGraph debug print All",
            py::arg("graph_capsule"),
            py::arg("filename") = "");
            
    m.def("manipulation_Llama_3_1_8B_Instruct_graph", &manipulation_Llama_3_1_8B_Instruct_graph,
        "PyTorch CUDAGraph debug print",
            py::arg("graph_capsule"),
            py::arg("original_batch"),
            py::arg("new_batch"),
            py::arg("filename") = "");

    m.def("manipulation_huggingface_graph", &manipulation_huggingface_graph,
        "Apply grid/block dims from parsed DOT text file",
            py::arg("graph_capsule"),
            py::arg("batch"),
            py::arg("filename") = "",
            py::arg("apply_block") = false);

    m.def("inspect_cutlass_gemm_params", &inspect_cutlass_gemm_params, 
          "Dump raw memory of Cutlass GEMM kernel parameters",
        py::arg("graph_capsule")); 

    m.def("debug_all_graph_nodes", &debug_all_graph_nodes, 
          "Dump raw memory of Cutlass GEMM kernel parameters",
        py::arg("graph_capsule"));   

    m.def("cuda_graph_debug_print", &cuda_graph_debug_print,
          "PyTorch CUDAGraph debug print",
          py::arg("cuda_graph"),
          py::arg("filename") = "");
    
    // 그래프 조작 기능
    m.def("get_graph_nodes_info", &get_graph_nodes_info,
          "Get list of node information dictionaries",
          py::arg("graph_capsule"));
    
    m.def("modify_kernel_node_grid", &modify_kernel_node_grid,
          "Modify kernel node grid dimensions (-1 to keep original)",
          py::arg("graph_capsule"),
          py::arg("node_index"),
          py::arg("grid_x") = -1,
          py::arg("grid_y") = -1,
          py::arg("grid_z") = -1);
    
    m.def("modify_graph_for_batch", &modify_graph_for_batch,
          "Auto-modify all kernel nodes for new batch size",
          py::arg("graph_capsule"),
          py::arg("original_batch"),
          py::arg("new_batch"));
    
    m.def("reinstantiate_graph", &reinstantiate_graph,
          "Create new GraphExec from modified graph",
          py::arg("graph_capsule"));
    
    m.def("get_node_count", &get_node_count,
          "Get number of nodes in graph",
          py::arg("graph_capsule"));

    m.def("dump_runtime_grid_values", &dump_runtime_grid_values,
          "Dump actual runtime grid values for all kernel nodes",
          py::arg("graph_capsule"));

    m.def("print_graph_info", &print_graph_info,
          "Get formatted string of graph information",
          py::arg("graph_capsule"));
    
    // DOT 플래그 상수 (정수 리터럴로 직접 정의)
    m.attr("DOT_FLAGS_DEFAULT") = 0u;
    m.attr("DOT_FLAGS_VERBOSE") = 1u;
    m.attr("DOT_FLAGS_RUNTIME_TYPES") = 2u;
    m.attr("DOT_FLAGS_KERNEL_NODE_PARAMS") = 4u;
    m.attr("DOT_FLAGS_MEMCPY_NODE_PARAMS") = 8u;
    m.attr("DOT_FLAGS_MEMSET_NODE_PARAMS") = 16u;
    m.attr("DOT_FLAGS_HANDLES") = 1024u;
}
